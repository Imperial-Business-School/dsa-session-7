{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trump tweets\n",
    "\n",
    "_Data Structures and Algorithms_\n",
    "\n",
    "_Imperial College Business School_\n",
    "\n",
    "\n",
    "---\n",
    "In this optional section, we will practice dealing with JSON data from Twitter's API.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "This part of the session is optional and meant to be open-ended. You don't need to submit anything. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trump tweets, JSON edition\n",
    "\n",
    "Earlier in the course, we looked at some of Donald Trump's tweets that had been conveniently packaged into a CSV file that we could open as a spreadsheet. The dataset we used ended in summer 2016. What if we wanted to analyse more recent tweets? We could do this by registering for access to Twitter's API (application programming interface; Twitter's interface for anyone to access its data) and downloading the data directly using one of the libraries that Python users have developed for accessing the API. \n",
    "\n",
    "We won't register for the API now. Instead, we'll use data maintained by Github user bpb27. \n",
    "\n",
    "The data that we'll use has been cleaned and condensed, but resembles the output from the Twitter API. Instead of CSV, the API gives data in JSON format. We've included the file condensed_2016.json downloaded from Github in the zip file.\n",
    "\n",
    "What is JSON data, and how can we load it into Python?\n",
    "\n",
    "### JSON\n",
    "\n",
    "JSON (JavaScript Object Notation, \"Jason\") is a common format for semi-structured data on the web. Many APIs provide data as JSON. We can open a JSON file in any text editor. It will look something like this.\n",
    "\n",
    "```json\n",
    "{\"countries\":\n",
    "  [\n",
    "  {\"Germany\": \"Berlin\"},\n",
    "  {\"France\": \"Paris\"},\n",
    "  {\"Italy\": \"Rome\"}\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "This looks very much like a Python data structure with nested dictionaries and lists. A tweet from Twitter's API will look similar (some fields only here):\n",
    "\n",
    "```json\n",
    "{\"source\": \"Twitter for iPhone\",\n",
    "\"id_str\": \"815271067749060609\",\n",
    "\"text\": \"RT @realDonaldTrump: Happy Birthday @DonaldJTrumpJr!\\nhttps://t.co/uRxyCD3hBz\",\n",
    "\"created_at\": \"Sat Dec 31 18:59:04 +0000 2016\",\n",
    "\"retweet_count\": 9529,\n",
    "\"in_reply_to_user_id_str\": null,\n",
    "\"favorite_count\": 0,\n",
    "\"is_retweet\": true}\n",
    "```\n",
    "JSON is more flexible than CSV. For example, some tweets might not include some data fields. In a CSV file, we would still include them in tabular form. In JSON, the specific key-value pair would be absent.\n",
    "\n",
    "We can read the JSON file to Python as we would a text file, or open it in Notepad or another text editor. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_name = 'condensed_2016.json'\n",
    "with open(json_file_name, encoding='utf8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Print first characters of resulting string \n",
    "print(text[0:500]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having read the file, we could parse through the string looking for  different aspects of each tweet. But it's much more convenient to use a library that directly exploits the structure of JSON. This is called simply the json library. We import it using the import statement, and use its methods to load data into Python's data structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "json_file_name = 'condensed_2016.json'\n",
    "with open(json_file_name, encoding='utf8') as f:\n",
    "    tweet_data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a Python list of dictionaries containing the tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now ready to study patterns in the tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Up all night?\n",
    "\n",
    "Let's start by analysing President Trump's sleep patterns. We will create a count of the number of tweets by hour of the day. \n",
    "\n",
    "Here's how you can get the hour from a tweet timestamp using the `datetime` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Get first tweet\n",
    "tw = tweet_data[0]\n",
    "print(tw)\n",
    "# We see the timestamp is at the field 'created_at'\n",
    "\n",
    "# Get timestamp of the tweet\n",
    "date_str = tw['created_at']\n",
    "print(date_str)\n",
    "\n",
    "# Make into datetime object, get the attributes of the result\n",
    "dt = datetime.strptime(date_str,'%a %b %d %H:%M:%S +0000 %Y') # specify format of time string\n",
    "print(dt.year, dt.month, dt.day, dt.hour)\n",
    "type(dt.hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task is to count all tweets by hour. One way to do this is creating a dictionary with keys as hours and values as counts.\n",
    "\n",
    "#### Sidebar: dictionary comprehension\n",
    "\n",
    "Recall that Python has a convenient way of reducing the work we need to do for writing loops called _comprehensions_. We can write a loop to create a dictionary in a single line as follows. The same kind of thing can be done to create lists too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionary of zero hourly counts using dictionary comprehension\n",
    "# Dictionary specified as key->hour, value->zero for each hour value in the range\n",
    "hourly_counts = {hour:0 for hour in range(24)}\n",
    "hourly_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may find this initialization useful in calculating the counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Your code here. \n",
    "\n",
    "# Initialize hourly_counts as above\n",
    "\n",
    "# loop through tweets in tweet_data\n",
    "# within loop: get timestamp of tweet as above\n",
    "# within loop: get hour as above\n",
    "# within loop: add one to dictionary value for relevant hour\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the most common hour for tweeting? What can you say about the President's sleeping patterns? What additional analysis would you do?\n",
    "\n",
    "You can use `matplotlib` to plot the result. You can do a line chart following [the first example here](https://matplotlib.org/users/pyplot_tutorial.html), or a bar chart following [this example](https://pythonspot.com/en/matplotlib-bar-chart/).\n",
    "\n",
    "You could also check how this pattern changes over different months."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Who's tweeting?\n",
    "\n",
    "It appears that there are different sources for the tweets in the `source` field of the data. \n",
    "\n",
    "Create an hourly count of tweets by the different sources. Can you infer what this suggests about Trump's personal phone and the one his office uses for tweeting?\n",
    "\n",
    "Let's first find all the sources that are in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = set()\n",
    "for tweet in tweet_data:\n",
    "    if tweet['source'] not in sources:\n",
    "        sources.add(tweet['source'])   \n",
    "print(sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which are the most common sources and what do their timings suggest about usage?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Initialize dictionary (or multiple) like above\n",
    "# Loop through tweets and add to counts like above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Who's tweeting what?\n",
    "\n",
    "How do the contents of Mr Trump's tweets change depending on the source? We could do some really sophisticated analysis here through [sentiment analysis](http://text-processing.com/demo/sentiment/) of the tweet texts. For the purposes of this exercise, do the following calculations by tweet source:\n",
    "\n",
    "1. Find the fraction of tweets containing the word 'dumb' in either upper or lower case.\n",
    "\n",
    "2. Repeat for words you'd like, for example the ones suggested below.\n",
    "\n",
    "You can also repeat the analysis by source and hour, or look at different words or mentions of different Twitter users. \n",
    "\n",
    "Note you probably want to count both upper and lower case words together.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "words = ['dumb', 'brexit', '#makeamericagreatagain', 'guns', 'dead', '#crookedhillary']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
