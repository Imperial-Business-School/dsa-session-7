{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Pandas\n",
    "\n",
    "_Data Structures and Algorithms_\n",
    "\n",
    "_Imperial College Business School_\n",
    "\n",
    "\n",
    "---\n",
    "In this section, we will look at `pandas`, a library that represents data in higher level structures to allow convenient and versatile data analysis. It is recommended that you visit this notebook over the next weeks, as it will support you with completing Homework 2. Here we will cover the use of pandas for loading data, representing it with common structures (pandas series and dataframes), and manipulating/accessing data within these structures. \n",
    "\n",
    "But first, we'll explore a new way of working in Python.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Readings:**\n",
    "\n",
    "Reda, Greg. Intro to pandas data structures.\n",
    "\n",
    "-   <http://www.gregreda.com/2013/10/26/intro-to-pandas-data-structures/>\n",
    "\n",
    "Evans, Julia. Pandas cookbook.\n",
    "\n",
    "-   <https://github.com/jvns/pandas-cookbook>\n",
    "\n",
    "-   Chapters 1-2.\n",
    "\n",
    "\n",
    "***Optional Readings:***\n",
    "\n",
    "Moffitt, Chris. Common Excel Tasks Demonstrated in Pandas.\n",
    "\n",
    "-   <http://pbpython.com/excel-pandas-comp.html>\n",
    "\n",
    "10 Minutes to pandas\n",
    "\n",
    "-   A succinct reference for key tools in the package.\n",
    "\n",
    "-   <http://pandas.pydata.org/pandas-docs/stable/10min.html>\n",
    "\n",
    "Augsburger, Tom. Modern pandas.\n",
    "\n",
    "-   Advanced material on best practices.\n",
    "\n",
    "-   <http://tomaugspurger.github.io/modern-1.html>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter Notebooks\n",
    "\n",
    "So far we've been using the Python console and the VS Code IDE to write code. Now we'll introduce another convenient way to both write code and present it: the Jupyter Notebook. Briefly, the notebook is an interactive computing environment that allows us to include \"live\" Python code that the user can run, combined with explanations, narrative text, equations, etc. Notebooks can also easily be exported to html and PDF formats. Due to this flexibility, they have become popular in various contexts: for example, they are often used in analytics teams to share and present ideas. This document and all the other html files have been written as Jupyter Notebooks.\n",
    "\n",
    "The main visible component of the notebook is a web application, which is your interface with the notebook. It allows you to both create and manage documents and write and run Python code. All of this happens in your browser. The web application uses a process called Python kernel to run your code - essentially there is an IPython \"shell\" (resembling the Python console) running in the background. The documents have the extension `.ipynb`. \n",
    "\n",
    "The Jupyter Notebook format is not limited to Python, but can be used with other languages including R, as long as the corresponding kernel has been installed.\n",
    "\n",
    "Jupyter Notebooks are supported by VS Code. You will need the Jupyter extension, but this is intalled by default in your Codespace.\n",
    "\n",
    "You can also use Jupyter lab, which is a more modern version of the notebook interface. You can launch it from the command line by typing `jupyter lab`, which should trigger a pop-up asking you to **Open Browser**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook features\n",
    "\n",
    "Let's go through the main functionalities of the Notebook.\n",
    "\n",
    "\n",
    "When you opened the file `pandas.ipynb`, you might notice it looks similar to the HTML files we refer to each week. We see text as usual, but the snippets of Python code can be run and edited. Indeed, you can also edit the entire document to make comments, add new code cells, and so on. \n",
    "\n",
    "### Code cells\n",
    "\n",
    "A Jupyter notebook is organized in cells. Some cells contain text and others code snippets. You can run a cell containing Python code by hovering over it and pressing the \"Play\" button that appears left of it. Or by clicking on the code cell and using `Shift + Enter` (which moves you to the next cell) or `Ctrl + Enter` (which keeps you in place). Try editing the code below and running it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Hey!')\n",
    "print(1 + 2)\n",
    "1 + 8\n",
    "4 - 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running a code cell will display everything that you `print` and the result of the last expression that was evaluated, here 4-5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markdown (text) cells\n",
    "\n",
    "You can edit a text cell's contents by double-clicking on it. When you're done editing, use `Shift + Enter` to render the cell. The text cells support [Markdown](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet) syntax. Try editing the text in the cell below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Double click to edit this cell._\n",
    "\n",
    "**Bold text**\n",
    "\n",
    "### A header\n",
    "\n",
    "#### A smaller header\n",
    "\n",
    "Some more text.\n",
    "\n",
    "When you're done editing, hit `Esc` (or `Shift+Enter`) to render the cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating new cells\n",
    "\n",
    "You can add a new cell by hovering over the bottom of an existing cell, or using the buttons in the tool bar at the top of the editor panel. You can remove a cell using the bin icon that appears top-right of the cell when you hover over it.\n",
    "\n",
    "### Saving the Notebook\n",
    "\n",
    "Saving the Notebook works like saving any file in VS Code. If you are in the Codespace, it will automatically save."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important: stopping code execution in Jupyter\n",
    "\n",
    "Let's try running some more code in the Notebook. Run the following cell using `Shift+Enter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 5\n",
    "while counter >=0:\n",
    "    counter = counter + 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will see that at the bottom of the cell Jupyter displays a timer. **This means that the code in the cell is still executing. While this is going on, you will not be able to run code from other cells.** \n",
    "\n",
    "What we've created above is an infinite loop that will never finish. The condition of the while loop will always remain `True`. **In order to stop Jupyter executing it, click on the Stop icon at the left of the cell.**\n",
    "\n",
    "You may need this later so make a note of this now. Try it again a few times: run the cell and stop its execution.\n",
    "\n",
    "If something goes more seriously wrong and the Notebook crashes, you can restart the Python Kernel from toolbar at the top of the editor panel. Notice that this will clear Python's memory so you would have to run all your code cells again from the beginning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## okpy in Notebooks\n",
    "\n",
    "This notebook is not graded as part of your session hand-ins. However, you will find some OK tests within this notebook, which you may use to check your understanding.\n",
    "\n",
    "First, let's connect the Notebook to OK. To do so, run the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Don't change this cell; just run it. \n",
    "# The result will give you directions on how to log in to the OK submission system.\n",
    "# Once you're logged in, OK should remember it for the duration of the session.\n",
    "import zipimport\n",
    "import importlib.util\n",
    "\n",
    "importer = zipimport.zipimporter('./ok')\n",
    "spec = importlib.util.spec_from_loader('client', importer)\n",
    "client = importlib.util.module_from_spec(spec)\n",
    "importer.exec_module(client)\n",
    "\n",
    "spec = importlib.util.spec_from_loader('client/api/notebook', importer)\n",
    "nb = importlib.util.module_from_spec(spec)\n",
    "importer.exec_module(nb)\n",
    "\n",
    "ok = nb.Notebook('ses06.ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas\n",
    "\n",
    "Pandas provides data analysis and statistical functionalities in Python. \n",
    "\n",
    "We will first introduce some core aspects of pandas using toy data, and then analyse a real data set. Always be sure to import the pandas package - by convention we give it a shorthand name using `as`. When we want to use the package, we can type `pd.` instead of `pandas.`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Here we generate some toy data. We will explore the numpy package later\n",
    "# # but for now, just know we are use it to generate some random data.\n",
    "import numpy as np\n",
    "\n",
    "# # We fix the seed so that the results are reproducible.\n",
    "# # Please do not change this code.\n",
    "np.random.seed(seed=9)\n",
    "# # Generate some toy data (sampled from a Gaussian distribution)\n",
    "values = np.random.randn(100, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much of the work we do with pandas revolves around the use of _DataFrames_ to organize data. A DataFrame is a 2-dimensional labeled data structure with columns of potentially different types. You can think of it like a spreadsheet. If you've used R, chances are you've already used dataframes. The functionalities are very similar. The data structures in pandas build on and wrap around most popular data-types of python, e.g. lists, so it's easy to move from one to another and call functions that work on a specific structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's use the data that we created above to create a DataFrame.\n",
    "dataframe = pd.DataFrame(data=values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's inspect our dataframe.\n",
    "# # For instance, you can get the shape of the dataframe, to see its dimensions.\n",
    "print(dataframe.shape)\n",
    "\n",
    "# # Some pandas methods have the same names as in standard Python, such as\n",
    "# # max, min, and sum. Other common methods are the median, mean, and std \n",
    "# # (standard deviation) methods.\n",
    "print(dataframe.max())\n",
    "\n",
    "# # The max value should be 2.45. But notice the result is not a simple value \n",
    "# # but a pandas data \"series\"\n",
    "print('Result type:', type(dataframe.max()))\n",
    "\n",
    "# # To get only the max value without the additional information, you \n",
    "# # could do: \n",
    "print(dataframe.max()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Dataframe summary\n",
    "\n",
    "**A.** What is the min value of the dataframe?\n",
    "\n",
    "**B.** What is the mean value of the dataframe?\n",
    "\n",
    "**C.** Now create a new DataFrame named `dataframe_10k` that includes a vector of 10000 elements sampled from a Gaussian as above. What is the mean value now? **Hint** Remember to copy the same seed as above to ensure that you create the same array as in the test. The random.seed and the creation of the matrix should be in the same cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Change the next line so that min_elem_df contains the min\n",
    "# element of dataframe. \n",
    "# The expected result is ONLY the min value.\n",
    "min_elem_df = ...\n",
    "\n",
    "# Change the next line so that mean_elem_df contains the mean\n",
    "# element of dataframe. \n",
    "# The expected result is ONLY the mean value.\n",
    "mean_elem_df = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Please do not modify the line below (allows us to replicate the results).\n",
    "np.random.seed(seed=9)\n",
    "\n",
    "# The lines below concern part C of Question 1. \n",
    "# Modify the line below so that it creates the dataframe of 10k elements\n",
    "# as mentioned in the description (part C above).\n",
    "dataframe_10k = ...\n",
    "\n",
    "# Change the next line so that mean_10k contains the mean\n",
    "# element of dataframe_10k. \n",
    "mean_10k = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Test cell; please do not change!\n",
    "_ = ok.grade('q1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've seen how a DataFrame is initiated and some methods that it includes. Here are some other key points to know:\n",
    "\n",
    "* In a dataframe, different data types (float, string, datetime) are allowed in the same structure.\n",
    "* Pandas offers a  plethora of high-level functionality, e.g. grouping data by conditions (using the groupby method) and combining datasets with merge and join methods. We will see these methods later.\n",
    "* The data (columns/rows) can have labels in pandas - they are explicitly coded in the structure of a dataframe.\n",
    "\n",
    "Let's study an example that utilises some of these ideas. We'll create a small dataset of a few countries with the countries names, population, GDP, a d country codes. This sounds like a problem where we might use dictionary. Indeed the dictionary is convenient for housing this kind of data. However, data/number processing with a dictionary can be cumbersome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "d1 = {}\n",
    "d1['countries'] = ['UK', 'France', 'Spain', 'Netherlands']\n",
    "d1['codes'] = ['uk', 'fr', 'es', 'nl']\n",
    "# # the population is measured in millions\n",
    "d1['population'] = [65.6, 66.9, 46.6, 17.0]\n",
    "# # the gdp is measured in billions\n",
    "d1['gdp'] = [2619, 2465, 1232, 770]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's create a dataframe now with that data.\n",
    "# # DataFrame includes a convenience constructor that\n",
    "# # just accepts the dictionary data and creates\n",
    "# # the same structure as in the previous example.\n",
    "countries_data = pd.DataFrame(d1)\n",
    "\n",
    "print(countries_data['gdp'])\n",
    "countries_data # Notebook gives a nice HTML table of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Additionally, we can call the aggregation methods as above, but now we get\n",
    "# # a result per column (which makes sense, we do not want to average\n",
    "# # gdps together with populations). Set numeric_only to True to avoid errors.\n",
    "countries_data.mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: More summaries\n",
    "\n",
    "**A.** What is the sum of the populations in the `countries_data`?\n",
    "\n",
    "**B.** What is the standard deviation of the gdp's in the `countries_data`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Change the next line so that sum_pop_countries_data computes the sum of\n",
    "# the populations from countries_data, rounded to one decimal.\n",
    "sum_pop_countries_data = ...\n",
    "\n",
    "# Change the next line so that std_gdp_countries_data computes the standard deviation of\n",
    "# the gdp from countries_data, rounded to one decimal.\n",
    "std_gdp_countries_data = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Test cell; please do not change!\n",
    "_ = ok.grade('q2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File loading, data processing with Pandas\n",
    "\n",
    "Now that you've become familiar with Dataframe, let's scale up our exploration and download a real dataset. We will use the Titanic dataset from the Kaggle Getting Started challenge at:\n",
    "\n",
    "https://www.kaggle.com/c/titanic-gettingStarted\n",
    "\n",
    "The dataset is included as `titanic.csv` and is located in the `data/` directory. To load the file we need to point at the file's location. Relative to this notebook, it is in a directory called `data`, so we prefix the filename with that information, giving us `'data/titanic.csv'`. This is called a *relative path* since it describes the file location relative to this notebook's location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's load the first csv file. \n",
    "data = pd.read_csv('data/titanic.csv')\n",
    "\n",
    "# # Printing the shape of the dataset we have just loaded.\n",
    "print(data.shape)\n",
    "\n",
    "# # The first step in data analysis is the exploration step.\n",
    "# # We want to verify that a) our dataset is appropriately loaded,\n",
    "# # b) get a sense of what values it has.\n",
    "# # Let's display the 5 first rows:\n",
    "data.head(5)\n",
    "# # (When we run this in the Notebook, we will get a nice \n",
    "# #  HTML representation of the table.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract some info from what we have just printed:\n",
    "\n",
    "As you've noticed, each row has an id, starting from zero, and the data columns have names that help us categorise the values of the columns. For instance, the fourth column includes the names of the passengers and the sixth their ages. \n",
    "In the Cabin column, notice that there are some 'NaN' values. 'NaN' typically denotes a missing value in pandas.\n",
    "\n",
    "Pandas includes a lot of built-in tools and methods that produce useful insights for our data. For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pandas also allow us to plot values directly. \n",
    "# # Let's plot a histogram of the age of the passengers\n",
    "# # pandas can create plots using a package called matplotlib\n",
    "# # (matplotlib must be installed in your environment)\n",
    "data.hist(column='Age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For accessing a specific value of a column you can you use the at[] property or the get() method, like this:\n",
    "\n",
    "```python\n",
    ">>> data.at[0, 'Age']\n",
    "22\n",
    ">>> data.get('Age')\n",
    "# the entire column\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: Accessing a dataframe\n",
    "\n",
    "**A.** What is the age of the 10th passenger (i.e. PassengerId is 10)?\n",
    "\n",
    "**B.** What is the cabin value for the 194th passenger?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Change the next line so that age_passenger_10 computes the age of\n",
    "# the 10th passenger.\n",
    "age_passenger_10 = ...\n",
    "\n",
    "# Change the next line so that cabin_194_passenger computes the \n",
    "# cabin number of the 194th passenger.\n",
    "cabin_194_passenger = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Test cell; please do not change!\n",
    "_ = ok.grade('q3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: More accessing\n",
    "\n",
    "Fill in the line of code below and then test it using the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the next line so that it computes ticket number/id of\n",
    "# the 100th passenger\n",
    "ticket_i_th_passenger = ...\n",
    "\n",
    "# We've put this line in this cell so that it will print\n",
    "# the value you've given to ticket_i_th_passenger when you\n",
    "# run it.  You don't need to change this.\n",
    "ticket_i_th_passenger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Test cell; please do not change!\n",
    "_ = ok.grade('q4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data modification with pandas\n",
    "\n",
    "In addition to parsing data, pandas can be used to modify data tables. We will go through a few common methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's delete the first and the third \n",
    "# # passengers (remember the indexing in \n",
    "# # python starts from 0).\n",
    "data.drop([0, 2], axis=0).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Apart from that, you can also delete whole columns or rows.\n",
    "# # For instance, for your problem, the Cabin column might be \n",
    "# # irrelevant, let's delete it.\n",
    "data.drop(['Cabin'], axis=1).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now print the first five elements to check how the dataset looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a minute to consider what pandas have printed for you...\n",
    "\n",
    "You might have observed, that the 'Cabin' column that we deleted above (the result showed it was deleted above) is still there. You will also notice, that even the elements that we deleted (passengers 1 and 3) are also re-added. Or were they never deleted in the first place? \n",
    "\n",
    "By default in pandas `drop` is not \"inplace\": in other words, the function returns you a *copy* while the original is untouched. However, since the copy is of the same type, you can assign it to a new variable, which will now contain only the reduced elements/columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's check that the data type is the same.\n",
    "print(type(data))\n",
    "# # What about the return type from a drop operation?\n",
    "print(type(data.drop(['Cabin'], axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "Assign to the variable `reduced_data` the pandas matrix that does not include the columns of Cabin, Embarked and SibSp. Then execute the cell below for testing with the ok system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Change the next line so that it computes the reduced data matrix.\n",
    "reduced_data = ...\n",
    "\n",
    "# We've put this line in this cell so that it will print\n",
    "# the value you've given to reduced_data when you\n",
    "# run it.  You don't need to change this.\n",
    "reduced_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cell; please do not change!\n",
    "_ = ok.grade('q5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from deleting, you can also replace values by new ones. Remember that the main purpose of pandas is statistical computation, hence we often translate values to numbers that we know how to process. \n",
    "\n",
    "For instance, strings, such as 'male' or 'female' are not really useful for statistical analysis. We usually prefere to replace them with numerical values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace('male', 1).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with drop, the replace function returns a copy, so keep in mind that if you want to save them, you have to assign to a new variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # An alternative way to replace the data is the following:\n",
    "data['Sex'] = data['Sex'].map({'female': 1, 'male': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now assume that from an external source, you figure out the Nationality of the passengers and want to insert that information. Pandas allow you to insert new rows, and in contrast with the aforementioned methods, this is an in-place operation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Right after the Sex, we want to include a new field named 'Nationality'. \n",
    "# # Since most of the passengers are Irish, we will by default assign \n",
    "# # the label 'Irish' to them and refine for those that are not.\n",
    "data.insert(5, 'Nationality', 'Irish')\n",
    "\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have replaced the values of a complete column, however what if we want to perform some modifications in specific values per row (e.g. if a condition is true)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # Let's assume for a moment that the nationality of \n",
    "# # those with Age NaN is Other European (hence why there \n",
    "# # are no records of their age).\n",
    "# # We want to replace the default nationality with\n",
    "# # their known nationality.\n",
    "\n",
    "# # Don't worry about how this works for now, it will be clear when we cover numpy.\n",
    "import numpy as np\n",
    "for index, row in data.iterrows():\n",
    "    if np.isnan(data.loc[index, \"Age\"]):\n",
    "        data.loc[index, \"Nationality\"] = \"European\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # What we've done above is to replace some of the nationalities with 'European'. \n",
    "# # One property of pandas that we've utilised for that is the '.loc'.\n",
    "# # Let's explore that a bit more: \n",
    "print(data.loc[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be easily verified from the print above, this provides the whole row of the 4th passenger (as Python follows zero-based indexing). In other words, data.loc is a way to index a row or even a specific 'cell' inside the row as we did above with `data.loc[index, \"Nationality\"]'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # As typically done in higher level libraries in python, '.loc' offers a great deal of functionality. \n",
    "# # You can find furthr information by executing data.loc??\n",
    "help(data.loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can filter dataframes directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "european_bool = data['Nationality'] == 'European' # creates Booleans for each entry\n",
    "print(european_bool.head(10))\n",
    "# We could then pick only these records with \n",
    "europeans = data[european_bool]\n",
    "# If we want to count different values, we can do \n",
    "data['Nationality'].value_counts()\n",
    "# Counting how many non null values exist would be data['Nationality'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## All done!\n",
    "\n",
    "That's it for the recommended pandas exercises. For more practice, complete the optional exercises below. There is no submission required for the Pandas material."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional exercises\n",
    "\n",
    "### Question 6\n",
    "\n",
    "**A.** Can you replace the nationalit column with numbers? For instance, try to assign values such that Irish = 0, Other European = 1. \n",
    "\n",
    "**B.** How many people of European nationality are there? (Following the assumption above for the NaN in the age)\n",
    "\n",
    "**C.** For how many passengers do we have with Cabin information?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Change the next line so that it computes the number of\n",
    "# people with European nationality.\n",
    "n_european = ...\n",
    "\n",
    "# Change the next line so that it computes the number of\n",
    "# people for which we have cabin information.\n",
    "n_passengers_cabin = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Test cell; please do not change!\n",
    "_ = ok.grade('q6')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "\n",
    "Assign to the variable `only_pclass2` the pandas matrix that includes only the passengers with Pclass = 2. Then execute the cell below for testing with the ok system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Change the next line so that it computes a new dataframe\n",
    "# that includes only the people with Pclass = 2.\n",
    "# One way to use conditions in pandas is directly with data[CONDITION]\n",
    "only_pclass2 = ...\n",
    "\n",
    "# We've put this line in this cell so that it will print\n",
    "# the value you've given to only_pclass2 when you\n",
    "# run it.  You don't need to change this.\n",
    "only_pclass2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test cell; please do not change!\n",
    "_ = ok.grade('q7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra part: More Titanic\n",
    "\n",
    "The Codespace contains the files `titanic.csv` and `nationalities.csv`, inside the `data/` directory. The latter file contains nationalities of Titanic passengers. Note that this file was created solely for the purpose of learning within this course, and should not be used outside of the scope of the course. It does **not** reflect the real nationalities of the passengers.\n",
    "\n",
    "Load the files titanic.csv and nationalities.csv in the variables `data_org` and `data_nat` respectively. Remember we combine the **directory** with the **filename and extension** to create the **path to the file**. Use the cell below as instructed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Reads the file titanic.csv\n",
    "data_org = pd.read_csv('data/titanic.csv')\n",
    "\n",
    "# Reads the file nationalities.csv\n",
    "data_nat = pd.read_csv('data/nationalities.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced pandas dataframe processing\n",
    "\n",
    "When working on data analysis, we often need to combine information from different sources, or produce our own data and then combine them with other sources. The pandas library offers a great deal of methods to facilitate this process. We will study below the functionality of merging datasets. We will merge the titanic.csv (original file) and the nationalities.csv (data produced by our research). \n",
    "\n",
    "Before merging two datasets, we need to know exactly how these datasets are related, how they are structured and whether they already have some common fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # First, let's ensure that the two datasets have the same number of elements (passenger data).\n",
    "assert data_org.shape[0] == data_nat.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's print the heads of the two datasets to figure out if there are any common elements.\n",
    "data_org.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nat.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # We are ready to perform the merging. Observe that the datasets share a common column in\n",
    "# # the PassengerId, so we will use it to combine the data.\n",
    "data_new = data_org.merge(data_nat, on='PassengerId')\n",
    "\n",
    "# # Let's see what we've created now.\n",
    "data_new.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pandas offers several convenient methods for conditional selection and actions on them.\n",
    "# # For instance, above we worked on getting useful aggregate statistics\n",
    "# # over the whole dataset (do you remember the commands?).\n",
    "# # However, often we'd like to select only a subset of the data based on some condition. \n",
    "# # For instance, let's say we would like to print the average age per class.\n",
    "# # One way to do that would be to iterate over all the elements, create a list, sum them \n",
    "# # and then compute the average. \n",
    "# # But pandas conveniently allows us to do it with a single command. \n",
    "# # It works as follows: \n",
    "# # First we group the data by the class, then we ask pandas to compute the mean of the age.\n",
    "print(data_new.groupby(['Pclass'])['Age'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # In the command above, we've averaged both men and women based only on the Pclass.\n",
    "# # However, we could separate the two sexes and compute the mean for each sex.\n",
    "print(data_new.groupby(['Pclass', 'Sex'])['Age'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might have noted that in class three, the average age of each sex differs significantly with the mean being closer to the male average age. Intuitively, you expect to find more men in that class than women. However, what is the command to find the exact number of males in this class? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # We will now drop few columns that contain strings to mention few methods for statistical processing.\n",
    "data = data_new.drop(['Cabin', 'Name', 'Ticket', 'Embarked', 'Nationality', 'Sex'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # We can for example \"clip\" the values, i.e. restrict them in a chosen interval.\n",
    "# # Notice that some values were greater than our upper bound, but are now\n",
    "# # restricted to the maximum upper bound we set.\n",
    "data.clip(lower=0, upper=40).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # If the method we would like to apply to the data does not exist, we can use the \n",
    "# # '.apply' method that allows us to choose any function to be applied to each record.\n",
    "# # One way to do this is through an \"anonymous\" lambda function.\n",
    "# # This works as defining a function without an explicit name to apply to each record\n",
    "data[\"SurvivedPlusOne\"] = data[\"Survived\"].apply(lambda x: x + 1)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**. Who survived? Use the aggregation functions above to calculate survival probabilities based on fare classes, age, or fare paid.\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
